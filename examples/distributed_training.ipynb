{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLX Distributed Training Tutorial\n",
    "\n",
    "This notebook provides a comprehensive guide to using the MLX Distributed Training framework for training large language models across multiple Apple Silicon devices.\n",
    "\n",
    "## What You'll Learn\n",
    "1. Setting up distributed training environment\n",
    "2. Configuring model and training parameters\n",
    "3. Implementing efficient data loading\n",
    "4. Managing memory and performance\n",
    "5. Monitoring training progress\n",
    "6. Handling distributed communication\n",
    "\n",
    "## Prerequisites\n",
    "- macOS Sonoma 14.0+\n",
    "- Python 3.12+\n",
    "- MLX 0.20.0+\n",
    "- High-speed network connection (10Gbps recommended)\n",
    "- Multiple Apple Silicon devices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "First, let's import required modules and verify our environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import mlx.core as mx\n",
    "from src.models import UnifiedModel\n",
    "from src.distributed import DistributedTrainer\n",
    "from src.monitoring import PerformanceDashboard\n",
    "from src.utils.network_utils import DistributedCommunicator\n",
    "from src.utils.memory_utils import AdvancedMemoryManager\n",
    "import psutil\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Verify MLX and Metal availability\n",
    "print(f\"MLX Version: {mx.__version__}\")\n",
    "print(f\"Metal Available: {mx.metal.is_available()}\")\n",
    "print(f\"Available Memory: {mx.metal.get_memory_limit() / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network Verification\n",
    "\n",
    "Before starting distributed training, let's verify network connectivity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize network communicator\n",
    "network_config = NetworkConfig(\n",
    "    primary_host=\"localhost\",\n",
    "    primary_port=29500\n",
    ")\n",
    "communicator = DistributedCommunicator(network_config)\n",
    "\n",
    "# Verify connection\n",
    "if communicator.verify_connection():\n",
    "    print(\"Network verification successful\")\n",
    "    print(f\"World Size: {communicator.world.size}\")\n",
    "    print(f\"Current Rank: {communicator.world.rank}\")\n",
    "else:\n",
    "    raise RuntimeError(\"Network verification failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Memory Management Setup\n",
    "\n",
    "Configure memory management for optimal performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize memory manager\n",
    "memory_config = MemoryConfig(\n",
    "    max_memory_gb=mx.metal.get_memory_limit() / (1024**3) * 0.9  # Use 90% of available memory\n",
    ")\n",
    "memory_manager = AdvancedMemoryManager(memory_config)\n",
    "\n",
    "# Monitor current memory usage\n",
    "def print_memory_stats():\n",
    "    metal_used = mx.metal.get_active_memory() / (1024**3)\n",
    "    metal_total = mx.metal.get_memory_limit() / (1024**3)\n",
    "    ram_used = psutil.Process().memory_info().rss / (1024**3)\n",
    "    \n",
    "    print(f\"Metal Memory Used: {metal_used:.2f} GB / {metal_total:.2f} GB\")\n",
    "    print(f\"RAM Used: {ram_used:.2f} GB\")\n",
    "\n",
    "print_memory_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Configuration\n",
    "\n",
    "Set up the model and training configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "config = {\n",
    "    \"model\": {\n",
    "        \"num_layers\": 24,\n",
    "        \"dims\": 1024,\n",
    "        \"num_heads\": 16,\n",
    "        \"vocab_size\": 50257,\n",
    "        \"max_seq_length\": 2048\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"batch_size\": {\n",
    "            \"primary\": 32,    # Larger device (e.g., Mac Studio)\n",
    "            \"secondary\": 16   # Smaller device (e.g., MacBook)\n",
    "        },\n",
    "        \"gradient_accumulation_steps\": 8,\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"warmup_steps\": 1000,\n",
    "        \"max_steps\": 100000,\n",
    "        \"eval_frequency\": 500,\n",
    "        \"save_frequency\": 1000\n",
    "    },\n",
    "    \"distributed\": {\n",
    "        \"world_size\": 2,\n",
    "        \"backend\": \"mpi\",\n",
    "        \"sync_weights_every\": 100  # Synchronize weights every N steps\n",
    "    },\n",
    "    \"monitoring\": {\n",
    "        \"enable_ui\": True,\n",
    "        \"port\": 8050,\n",
    "        \"alert_thresholds\": {\n",
    "            \"loss\": 10.0,\n",
    "            \"gpu_utilization\": 0.95,\n",
    "            \"memory_usage\": 0.9\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize Training Components\n",
    "\n",
    "Set up the trainer, model, and monitoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize trainer\n",
    "trainer = DistributedTrainer(config)\n",
    "\n",
    "# Create and optimize model\n",
    "model = UnifiedModel(config[\"model\"])\n",
    "model = memory_manager.optimize_memory_layout(model)\n",
    "\n",
    "# Setup monitoring dashboard\n",
    "dashboard = PerformanceDashboard(config[\"monitoring\"])\n",
    "\n",
    "print(\"Training components initialized successfully\")\n",
    "print_memory_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Loading and Processing\n",
    "\n",
    "Implement efficient data loading with streaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from datasets import load_dataset\n",
    "from src.training.data_utils import DataManager, DataConfig\n",
    "\n",
    "# Configure data loading\n",
    "data_config = DataConfig(\n",
    "    streaming=True,  # Enable streaming for large datasets\n",
    "    cache_dir=\"./cache\",\n",
    "    prefetch_batches=2\n",
    ")\n",
    "\n",
    "# Load and prepare dataset\n",
    "data_manager = DataManager(data_config)\n",
    "dataset = load_dataset(\"openwebtext\", split=\"train\", streaming=True)\n",
    "processed_dataset = data_manager.prepare_dataset(dataset)\n",
    "\n",
    "# Create data loader\n",
    "dataloader = data_manager.create_loader(\n",
    "    processed_dataset,\n",
    "    batch_size=config[\"training\"][\"batch_size\"][\"primary\" if trainer.world.rank == 0 else \"secondary\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Loop with Monitoring\n",
    "\n",
    "Run the training loop with comprehensive monitoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "async def train():\n",
    "    try:\n",
    "        # Training loop\n",
    "        for epoch in range(config[\"training\"][\"max_epochs\"]):\n",
    "            # Train one epoch\n",
    "            epoch_metrics = await trainer.train_epoch(dataloader, epoch)\n",
    "            \n",
    "            # Log metrics\n",
    "            print(f\"Epoch {epoch} - Loss: {epoch_metrics['avg_loss']:.4f}, \"\n",
    "                  f\"LR: {epoch_metrics['learning_rate']:.6f}\")\n",
    "            \n",
    "            # Check early stopping\n",
    "            if trainer.scheduler.should_stop(epoch_metrics['avg_loss'], epoch):\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "                \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted\")\n",
    "    finally:\n",
    "        # Clean shutdown\n",
    "        trainer.shutdown()\n",
    "        dashboard.shutdown()\n",
    "\n",
    "# Start training\n",
    "await train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyzing Results\n",
    "\n",
    "Review training metrics and performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get training summary\n",
    "metrics_summary = dashboard.get_summary()\n",
    "\n",
    "print(\"\\nTraining Summary:\")\n",
    "for metric, stats in metrics_summary.items():\n",
    "    print(f\"\\n{metric}:\")\n",
    "    for stat_name, value in stats.items():\n",
    "        print(f\"  {stat_name}: {value:.4f}\")\n",
    "\n",
    "# Create and display final plots\n",
    "training_plot = dashboard.create_training_plot()\n",
    "system_plot = dashboard.create_system_plot()\n",
    "\n",
    "training_plot.show()\n",
    "system_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Experiment with different model configurations\n",
    "2. Optimize batch sizes for your devices\n",
    "3. Implement custom monitoring metrics\n",
    "4. Explore advanced features:\n",
    "   - Gradient accumulation\n",
    "   - Dynamic batch sizing\n",
    "   - Custom evaluation metrics\n",
    "\n",
    "For more details, check out:\n",
    "- [Performance Tuning Guide](../docs/performance_tuning.md)\n",
    "- [API Documentation](../docs/api/)\n",
    "- [Best Practices](../docs/best_practices.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
